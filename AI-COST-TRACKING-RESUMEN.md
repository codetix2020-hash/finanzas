# Resumen: Sistema de Tracking de Costos de IA

---

## ‚úÖ TAREA 1: ARCHIVO CREADO

### `/packages/ai/lib/cost-tracker.ts`

El archivo est√° completo y listo para usar. Contiene:

- ‚úÖ Pricing de todos los modelos (Claude y OpenAI)
- ‚úÖ Funci√≥n `calculateCost()` para calcular costos
- ‚úÖ Funci√≥n `mapModelToProvider()` para mapear modelos a enums
- ‚úÖ Funci√≥n `trackAICall()` que registra en CostTracking y FinancialTransaction
- ‚úÖ Funci√≥n `generateRequestId()` para generar IDs √∫nicos
- ‚úÖ Funci√≥n `trackAIUsageFromFinish()` helper para usar desde callbacks

**Archivo completo:** Ver `packages/ai/lib/cost-tracker.ts`

---

## ‚úÖ TAREA 2: D√ìNDE SE HACEN LLAMADAS A IA

### üìç Archivo Principal

**Ruta:** `packages/api/modules/ai/procedures/add-message-to-chat.ts`

**L√≠neas relevantes:**
- L√≠nea 32: `const chat = await getAiChatById(chatId);`
- L√≠nea 38: `chat.organizationId` (puede ser `null`)
- L√≠neas 51-68: Llamada a `streamText()` con el callback `onFinish`

**C√≥mo se llama actualmente:**
```typescript
const response = streamText({
  model: textModel,
  messages: convertToModelMessages(messages),
  async onFinish({ text }) {
    await updateAiChat({ id: chatId, messages: [...] });
  },
});
```

**OrganizationId disponible en:**
- `chat.organizationId` (l√≠nea 38)
- Puede ser `null` para chats de usuario individual
- Ya est√° validado antes de la llamada a `streamText()`

---

## ‚úÖ TAREA 3: EJEMPLO DE INTEGRACI√ìN

### Modificaci√≥n del archivo `add-message-to-chat.ts`

**IMPORTANTE:** Solo hay **UN** archivo donde se hacen llamadas a IA actualmente.

#### Cambios necesarios:

**1. A√±adir imports (despu√©s de la l√≠nea 7):**
```typescript
import {
	generateRequestId,
	trackAIUsageFromFinish,
} from "@repo/ai/lib/cost-tracker";
```

**2. Generar requestId y obtener modelId (antes de streamText, l√≠nea 51):**
```typescript
const requestId = generateRequestId();
// El modelo actual es "gpt-4o-mini" definido en packages/ai/index.ts
const modelId = "gpt-4o-mini";
```

**3. Modificar el callback onFinish (l√≠nea 56):**
```typescript
async onFinish({ text, usage }) {
	// Trackear costo de IA si hay organizationId
	if (chat.organizationId) {
		await trackAIUsageFromFinish({
			organizationId: chat.organizationId,
			modelId,
			usage,
			endpoint: "/api/rpc/ai/chats/{chatId}/messages",
			requestId,
		});
	}

	// L√≥gica original de guardar mensaje
	await updateAiChat({
		id: chatId,
		messages: [
			...messages,
			{
				role: "assistant",
				parts: [{ type: "text", text }],
			},
		],
	});
},
```

---

## üìã C√ìDIGO COMPLETO MODIFICADO

Aqu√≠ est√° el archivo completo con todos los cambios aplicados:

```typescript
import { ORPCError, streamToEventIterator } from "@orpc/client";
import {
	convertToModelMessages,
	streamText,
	textModel,
	type UIMessage,
} from "@repo/ai";
import {
	generateRequestId,
	trackAIUsageFromFinish,
} from "@repo/ai/lib/cost-tracker";
import { getAiChatById, updateAiChat } from "@repo/database";
import z from "zod";
import { protectedProcedure } from "../../../orpc/procedures";
import { verifyOrganizationMembership } from "../../organizations/lib/membership";

export const addMessageToChat = protectedProcedure
	.route({
		method: "POST",
		path: "/ai/chats/{chatId}/messages",
		tags: ["AI"],
		summary: "Add message to chat",
		description:
			"Send all messages of the chat to the AI model to get a response",
	})
	.input(
		z.object({
			chatId: z.string(),
			messages: z.array(z.any() as z.ZodType<UIMessage>),
		}),
	)
	.handler(async ({ input, context }) => {
		const { chatId, messages } = input;
		const user = context.user;

		const chat = await getAiChatById(chatId);

		if (!chat) {
			throw new ORPCError("NOT_FOUND");
		}

		if (chat.organizationId) {
			const membership = await verifyOrganizationMembership(
				chat.organizationId,
				user.id,
			);

			if (!membership) {
				throw new ORPCError("FORBIDDEN");
			}
		} else if (chat.userId !== context.user.id) {
			throw new ORPCError("FORBIDDEN");
		}

		// Generar requestId para tracking
		const requestId = generateRequestId();
		// El modelo actual es "gpt-4o-mini" definido en packages/ai/index.ts
		const modelId = "gpt-4o-mini";

		const response = streamText({
			model: textModel,
			messages: convertToModelMessages(
				messages as unknown as UIMessage[],
			),
			async onFinish({ text, usage }) {
				// Trackear costo de IA si hay organizationId
				if (chat.organizationId) {
					await trackAIUsageFromFinish({
						organizationId: chat.organizationId,
						modelId,
						usage,
						endpoint: "/api/rpc/ai/chats/{chatId}/messages",
						requestId,
					});
				}

				// L√≥gica original de guardar mensaje
				await updateAiChat({
					id: chatId,
					messages: [
						...messages,
						{
							role: "assistant",
							parts: [{ type: "text", text }],
						},
					],
				});
			},
		});

		return streamToEventIterator(response.toUIMessageStream());
	});
```

---

## üìù LISTA DE ARCHIVOS DONDE SE LLAMA A IA

### Solo 1 archivo encontrado:

1. **`packages/api/modules/ai/procedures/add-message-to-chat.ts`**
   - Funci√≥n: `addMessageToChat`
   - Modelo usado: `textModel` (gpt-4o-mini)
   - OrganizationId: `chat.organizationId` (l√≠nea 38)

---

## üéØ RESUMEN DE FUNCIONAMIENTO

1. **Cuando se hace una llamada a IA:**
   - Se genera un `requestId` √∫nico
   - Se ejecuta `streamText()` con el modelo
   - En el callback `onFinish`, si hay `usage` y `organizationId`, se trackea

2. **Qu√© se registra:**
   - **CostTracking**: Detalles de la llamada (tokens, costo estimado, endpoint)
   - **FinancialTransaction**: Costo como transacci√≥n financiera (COST_API_CLAUDE o COST_API_OPENAI)

3. **Si no hay organizationId:**
   - No se trackea el costo (chats de usuario individual)

4. **Si no hay usage:**
   - No se trackea el costo (si la llamada falla o no proporciona usage)

---

## ‚úÖ ESTADO ACTUAL

- ‚úÖ Archivo `cost-tracker.ts` creado y exportado
- ‚è≠Ô∏è Pendiente: Integrar en `add-message-to-chat.ts` (aplicar cambios mostrados arriba)
- ‚úÖ Documentaci√≥n completa en `AI-COST-TRACKING-INTEGRATION.md`

---

## üîç NOTAS T√âCNICAS

- El modelo actual es **"gpt-4o-mini"** (OpenAI)
- Vercel AI SDK proporciona `usage` con `promptTokens` y `completionTokens` en `onFinish`
- El tracking no interrumpe el flujo si falla (solo loguea el error)
- Solo se trackean llamadas de organizaciones (no usuarios individuales)

